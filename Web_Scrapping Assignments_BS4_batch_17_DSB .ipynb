{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Librarires \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 . Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_scrap (url):\n",
    "    page = requests.get(url)\n",
    "    print(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    title = soup.find_all(['h1','h2','h3','h4','h5'])\n",
    "    title_h =[]\n",
    "    for i in title :\n",
    "        print('Heading',title.index(i))\n",
    "        print('************************')\n",
    "        print(i.text)\n",
    "        \n",
    "     \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = \"http://en.wikipedia.org/wiki/Main_Page\"\n",
    "headings = wiki_scrap(chk)\n",
    "print(headings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 .Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_hollywood(url):\n",
    "    html = url\n",
    "    page = requests.get(html)\n",
    "    print('Responce received',page)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    mov_lst = soup.find_all('div',class_ ='lister-item mode-detail')\n",
    "    print('Scrapping Completed')\n",
    "    movie =[]\n",
    "    year =[]\n",
    "    rate = []\n",
    "    for i in mov_lst :\n",
    "        movie.append(i.h3.a.text)\n",
    "        year.append(i.h3.find('span',class_='lister-item-year text-muted unbold').text)\n",
    "        rate.append(i.find('span',class_ ='ipl-rating-star__rating').text)\n",
    "    IMDB_hollywood= pd.DataFrame({})\n",
    "    IMDB_hollywood['Name']=movie\n",
    "    IMDB_hollywood['IMDB rating']=rate\n",
    "    IMDB_hollywood['Year of release']=year\n",
    "    return IMDB_hollywood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calling Func\n",
    "print('lets find the list of best hollowood movies in IMDB')\n",
    "url ='https://www.imdb.com/list/ls091520106/'\n",
    "list_movie = imdb_hollywood(url)\n",
    "list_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_bollywood(url):\n",
    "    html = url\n",
    "    page = requests.get(html)\n",
    "    print('Responce received',page)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    mov_lst = soup.find_all('div',class_ ='lister-item mode-detail')\n",
    "    print('Scrapping Completed')\n",
    "    movie =[]\n",
    "    year =[]\n",
    "    rate = []\n",
    "    for i in mov_lst :\n",
    "        movie.append(i.h3.a.text)\n",
    "        year.append(i.h3.find('span',class_='lister-item-year text-muted unbold').text)\n",
    "        rate.append(i.find('span',class_ ='ipl-rating-star__rating').text)\n",
    "    IMDB_bollywood= pd.DataFrame({})\n",
    "    IMDB_bollywood['Name']=movie\n",
    "    IMDB_bollywood['IMDB rating']=rate\n",
    "    IMDB_bollywood['Year of release']=year\n",
    "    return IMDB_bollywood\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FUNCTION CALLING \n",
    "print('lets find the list of best Hindi movies in IMDB')\n",
    "url =\"https://www.imdb.com/list/ls009997493/\"\n",
    "html = imdb_bollywood(url)\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 .Write a python program to scrap book name, author name, genre and book review of any 5 books from\n",
    "‘www.bookpage.com’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_review(url) :\n",
    "    page= requests.get(url)\n",
    "    print (page)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    print ('Web Scrapping completed')\n",
    "    book_lst = soup.find_all('div',class_ ='row-fluid article-row')\n",
    "    Book_name= []\n",
    "    Author_name= []\n",
    "    Genre= []\n",
    "    Review = []\n",
    "    for  b in book_lst :\n",
    "        Book_name.append(b.h4.a.text.strip())\n",
    "        Author_name.append(b.p.text.strip())\n",
    "        Review.append(b.find('p',class_=\"excerpt\").text.strip()) \n",
    "        genre_part = b.find('p',class_='genre-links hidden-phone')\n",
    "        genre_all =genre_part.findChildren(\"a\" , recursive=False)\n",
    "        k = 'Genre :'\n",
    "        for i in genre_all:\n",
    "            k = k + i.text +' '\n",
    "        Genre.append(k)\n",
    "        if len(Book_name)>4 :\n",
    "            break\n",
    "        \n",
    "    Book_review =pd.DataFrame({})\n",
    "    Book_review['Book_name'] =Book_name\n",
    "    Book_review['Author_name']=Author_name\n",
    "    Book_review['Genre'] =Genre\n",
    "    Book_review['Review']=Review\n",
    "    return Book_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('**** Books and Review ****')\n",
    "url = 'https://bookpage.com/reviews'\n",
    "review = book_review(url)\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "###   \n",
    "###   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def men_team_rtgs(url):\n",
    "    page =requests.get(url)\n",
    "    print('Response received :',page)\n",
    "    soup =BeautifulSoup(page.content)\n",
    "    rank=[]\n",
    "    country=[]\n",
    "    matches =[]\n",
    "    points =[]\n",
    "    rating=[]\n",
    "    others =[]\n",
    "    best_team = soup.find_all('tr',class_=\"rankings-block__banner\")\n",
    "    for i in best_team :\n",
    "        rnk =i.find('td',class_='rankings-block__banner--pos')\n",
    "        rank.append(rnk.text)\n",
    "        ctry = i.find('span',class_ ='u-hide-phablet')\n",
    "        country.append(ctry.text.strip())\n",
    "        mtch = i.find('td',class_ ='rankings-block__banner--matches')\n",
    "        matches.append(mtch.text.strip())\n",
    "        pts = i.find('td',class_ ='rankings-block__banner--points')\n",
    "        points.append(pts.text.strip())\n",
    "        rate = i.find('td',class_ ='rankings-block__banner--rating u-text-right')\n",
    "        rating.append(rate.text.strip())\n",
    "    team_odi = soup.find_all('tr',class_='table-body')\n",
    "    for i in team_odi :\n",
    "        rnk =i.find('td',class_='table-body__cell table-body__cell--position u-text-right')\n",
    "        rank.append(rnk.text)\n",
    "        ctry = i.find('span',class_ ='u-hide-phablet')\n",
    "        country.append(ctry.text.strip())\n",
    "        rate = i.find('td',class_ ='table-body__cell u-text-right rating')\n",
    "        rating.append(rate.text.strip())\n",
    "        other = i.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "        for j in other :\n",
    "            others.append(j.text)\n",
    "        if len(rating) == 10:\n",
    "            break\n",
    "    mtch = others[0::2]\n",
    "    pnts = others[1::2]\n",
    "    matches =matches.extend(mtch)\n",
    "    points =points.extend(pnts)\n",
    "    ODI_MEN_TEAM_RATINGS = pd.DataFrame([])\n",
    "    ODI_MEN_TEAM_RATINGS[\"rank\"] =rank\n",
    "    ODI_MEN_TEAM_RATINGS[\"country\"] =country\n",
    "    ODI_MEN_TEAM_RATINGS[\"matches\"] =matches\n",
    "    ODI_MEN_TEAM_RATINGS[\"points\"] =points\n",
    "    ODI_MEN_TEAM_RATINGS[\"rating\"] =rating\n",
    "    return ODI_MEN_TEAM_RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****** ICC TEAM RATING MEN ODI ')\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "ICC_MEN_ODI_TEAM_RANK= men_team_rtgs(url)\n",
    "ICC_MEN_ODI_TEAM_RANK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####  ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_men_bat_odi(url) :\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    w_best_bat =  soup.find_all('tr',class_='rankings-block__banner')\n",
    "    rank =[]\n",
    "    name=[]\n",
    "    country=[]\n",
    "    points =[]\n",
    "    for i in w_best_bat :\n",
    "        rnk = i.find('td',class_ ='rankings-block__position')\n",
    "        nme = i.find('div',class_ ='rankings-block__banner--name-large')\n",
    "        ctr = i.find('div',class_ ='rankings-block__banner--nationality')\n",
    "        pts = i.find('div',class_ ='rankings-block__banner--rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "    w_bat =  soup.find_all('tr',class_='table-body')\n",
    "    for i in w_bat :\n",
    "        rnk = i.find('td',class_ ='table-body__cell table-body__cell--position u-text-right')\n",
    "        nme = i.find('a')\n",
    "        ctr = i.find('span',class_ ='table-body__logo-text')\n",
    "        pts = i.find('td',class_ ='table-body__cell rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "        if len(points) == 10:\n",
    "            break\n",
    "    ODI_MEN_ODI__BAT_Ratings = pd.DataFrame([])\n",
    "    ODI_MEN_ODI__BAT_Ratings[\"Position\"] =rank\n",
    "    ODI_MEN_ODI__BAT_Ratings[\"Player Name\"] =name\n",
    "    ODI_MEN_ODI__BAT_Ratings[\"Team\"] =country\n",
    "    ODI_MEN_ODI__BAT_Ratings[\"Rating\"] =points\n",
    "    return ODI_MEN_ODI__BAT_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ODI BATESMEN RATING')\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "rank =icc_men_bat_odi(url)\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_men_bowl_odi(url) :\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    best_bowl= soup.find_all('tr',class_='rankings-block__banner')\n",
    "    rank =[]\n",
    "    name=[]\n",
    "    country=[]\n",
    "    points =[]\n",
    "    for i in best_bowl :\n",
    "        rnk = i.find('td',class_ ='rankings-block__position')\n",
    "        nme = i.find('div',class_ ='rankings-block__banner--name-large')\n",
    "        ctr = i.find('div',class_ ='rankings-block__banner--nationality')\n",
    "        pts = i.find('div',class_ ='rankings-block__banner--rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "    bowl_odi = soup.find_all('tr',class_='table-body')\n",
    "    for i in bowl_odi :\n",
    "        rnk = i.find('td',class_ ='table-body__cell table-body__cell--position u-text-right')\n",
    "        nme = i.find('a')\n",
    "        ctr = i.find('span',class_ ='table-body__logo-text')\n",
    "        pts = i.find('td',class_ ='table-body__cell rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "        if len(rank) == 10:\n",
    "            break\n",
    "    ODI_BOWLING_Ratings = pd.DataFrame([])\n",
    "    ODI_BOWLING_Ratings[\"Position\"] =rank\n",
    "    ODI_BOWLING_Ratings[\"Player Name\"] =name\n",
    "    ODI_BOWLING_Ratings[\"Team\"] =country\n",
    "    ODI_BOWLING_Ratings[\"Rating\"] =points\n",
    "    return ODI_BOWLING_Ratings     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ODI Bowler RATING')\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "rank =icc_men_bowl_odi(url)\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def women_team_rtgs(url):\n",
    "    page =requests.get(url)\n",
    "    print('Response received :',page)\n",
    "    soup =BeautifulSoup(page.content)\n",
    "    rank=[]\n",
    "    country=[]\n",
    "    matches =[]\n",
    "    points =[]\n",
    "    rating=[]\n",
    "    others =[]\n",
    "    best_team = soup.find_all('tr',class_=\"rankings-block__banner\")\n",
    "    for i in best_team :\n",
    "        rnk =i.find('td',class_='rankings-block__banner--pos')\n",
    "        rank.append(rnk.text)\n",
    "        ctry = i.find('span',class_ ='u-hide-phablet')\n",
    "        country.append(ctry.text.strip())\n",
    "        mtch = i.find('td',class_ ='rankings-block__banner--matches')\n",
    "        matches.append(mtch.text.strip())\n",
    "        pts = i.find('td',class_ ='rankings-block__banner--points')\n",
    "        points.append(pts.text.strip())\n",
    "        rate = i.find('td',class_ ='rankings-block__banner--rating u-text-right')\n",
    "        rating.append(rate.text.strip())\n",
    "    team_odi = soup.find_all('tr',class_='table-body')\n",
    "    for i in team_odi :\n",
    "        rnk =i.find('td',class_='table-body__cell table-body__cell--position u-text-right')\n",
    "        rank.append(rnk.text)\n",
    "        ctry = i.find('span',class_ ='u-hide-phablet')\n",
    "        country.append(ctry.text.strip())\n",
    "        rate = i.find('td',class_ ='table-body__cell u-text-right rating')\n",
    "        rating.append(rate.text.strip())\n",
    "        other = i.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "        for j in other :\n",
    "            others.append(j.text)\n",
    "        if len(rating) == 10:\n",
    "            break\n",
    "    mtch = others[0::2]\n",
    "    pnts = others[1::2]\n",
    "    matches =matches.extend(mtch)\n",
    "    points =points.extend(pnts)\n",
    "    ODI_WOMEN_TEAM_RATINGS = pd.DataFrame([])\n",
    "    ODI_WOMEN_TEAM_RATINGS[\"rank\"] =rank\n",
    "    ODI_WOMEN_TEAM_RATINGS[\"country\"] =country\n",
    "    ODI_WOMEN_TEAM_RATINGS[\"matches\"] =matches\n",
    "    ODI_WOMEN_TEAM_RATINGS[\"points\"] =points\n",
    "    ODI_WOMEN_TEAM_RATINGS[\"rating\"] =rating\n",
    "    return ODI_WOMEN_TEAM_RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****** ICC TEAM RATING WOMEN ODI ')\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "ICC_WOMEN_ODI_TEAM_RANK= women_team_rtgs(url)\n",
    "ICC_WOMEN_ODI_TEAM_RANK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_odi_bat(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    w_best_bat =  soup.find_all('tr',class_='rankings-block__banner')\n",
    "    rank =[]\n",
    "    name=[]\n",
    "    country=[]\n",
    "    points =[]\n",
    "    for i in w_best_bat :\n",
    "        rnk = i.find('td',class_ ='rankings-block__position')\n",
    "        nme = i.find('div',class_ ='rankings-block__banner--name-large')\n",
    "        ctr = i.find('div',class_ ='rankings-block__banner--nationality')\n",
    "        pts = i.find('div',class_ ='rankings-block__banner--rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "    w_bat =  soup.find_all('tr',class_='table-body')\n",
    "    for i in w_bat :\n",
    "        rnk = i.find('td',class_ ='table-body__cell table-body__cell--position u-text-right')\n",
    "        nme = i.find('a')\n",
    "        ctr = i.find('span',class_ ='table-body__logo-text')\n",
    "        pts = i.find('td',class_ ='table-body__cell rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "        if len(points) == 10:\n",
    "            break\n",
    "    ODI_Women_ODI__BAT_Ratings = pd.DataFrame([])\n",
    "    ODI_Women_ODI__BAT_Ratings[\"Position\"] =rank\n",
    "    ODI_Women_ODI__BAT_Ratings[\"Player Name\"] =name\n",
    "    ODI_Women_ODI__BAT_Ratings[\"Team\"] =country\n",
    "    ODI_Women_ODI__BAT_Ratings[\"Rating\"] =points\n",
    "    return ODI_Women_ODI__BAT_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "women_odi_bat= w_odi_bat(url)\n",
    "women_odi_bat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_odi_all (url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    w_best_all_odi =  soup.find_all('tr',class_='rankings-block__banner')\n",
    "    rank =[]\n",
    "    name=[]\n",
    "    country=[]\n",
    "    points =[]\n",
    "    for i in w_best_all_odi :\n",
    "        rnk = i.find('td',class_ ='rankings-block__position')\n",
    "        nme = i.find('div',class_ ='rankings-block__banner--name-large')\n",
    "        ctr = i.find('div',class_ ='rankings-block__banner--nationality')\n",
    "        pts = i.find('div',class_ ='rankings-block__banner--rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "    w_all_odi =  soup.find_all('tr',class_='table-body')\n",
    "    for i in w_all_odi :\n",
    "        rnk = i.find('td',class_ ='table-body__cell table-body__cell--position u-text-right')\n",
    "        nme = i.find('a')\n",
    "        ctr = i.find('span',class_ ='table-body__logo-text')\n",
    "        pts = i.find('td',class_ ='table-body__cell rating')\n",
    "        rank.append(rnk.text.strip())\n",
    "        name.append(nme.text.strip())\n",
    "        country.append(ctr.text.strip())\n",
    "        points.append(pts.text.strip())\n",
    "        if len(points) == 10:\n",
    "            break\n",
    "    ODI_Women_ODI_Ratings = pd.DataFrame([])\n",
    "    ODI_Women_ODI_Ratings[\"Position\"] =rank\n",
    "    ODI_Women_ODI_Ratings[\"Player Name\"] =name\n",
    "    ODI_Women_ODI_Ratings[\"Team\"] =country\n",
    "    ODI_Women_ODI_Ratings[\"Rating\"] =points\n",
    "    return ODI_Women_ODI_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "all_rounder_rank= w_odi_all(url)\n",
    "all_rounder_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  8. Write a python program to extract information about the local weather from the National Weather Service \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_service(url):\n",
    "    html = url\n",
    "    page = requests.get(html)\n",
    "    print('Website Status',page)\n",
    "    soup =  BeautifulSoup(page.content)\n",
    "    period_l=soup.find_all('p',class_ = 'period-name')\n",
    "    sdesc_l = soup.find_all('p','short-desc')\n",
    "    t_low =soup.find_all('p','temp temp-low')\n",
    "    t_high =soup.find_all('p','temp temp-high')\n",
    "    print('Scrapping Completed')\n",
    "    period =[]\n",
    "    for i in period_l:\n",
    "        period.append(i.text)\n",
    "    sdesc =[]\n",
    "    for j in sdesc_l:\n",
    "        sdesc.append(j.text)\n",
    "    min_temp = []\n",
    "    for k in t_low :\n",
    "        min_temp.append(k.text)\n",
    "    max_temp = []\n",
    "    for k in t_high :\n",
    "        max_temp.append(k.text)\n",
    "    temp_f = []\n",
    "    if period[0]=='Today' :\n",
    "        temp_f =[None]*(len(min_temp)+len(max_temp))\n",
    "        temp_f[::2]= max_temp\n",
    "        temp_f[1::2]= min_temp\n",
    "    else:\n",
    "        temp_f =[None]*(len(min_temp)+len(max_temp))\n",
    "        temp_f[::2]= min_temp\n",
    "        temp_f[1::2]= max_temp\n",
    "    weather = pd.DataFrame({})\n",
    "    weather['Period'] =period\n",
    "    weather['Tempareture'] =temp_f\n",
    "    #weather['Max_Temp'] =max_temp\n",
    "    weather['Short_Descriptipn'] =sdesc\n",
    "    return weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('**** Weather Forcast ****')\n",
    "weather_url = \"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YM2fa_LivDc\" \n",
    "report = weather_service(weather_url)\n",
    "pd.DataFrame(report) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  9. Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job   title, company name, CTC, and apply date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wb_scrap(url):\n",
    "    page = requests.get(url)\n",
    "    print(page)\n",
    "    soup= BeautifulSoup(page.content)\n",
    "    title_all = soup.find_all('div',class_= \"heading_4_5 profile\")\n",
    "    print ('Scrapping Completed')\n",
    "    job_title = []\n",
    "    for i in title_all :\n",
    "        job_title.append(i.text.replace('\\n',''))\n",
    "    comp_all = soup.find_all('a',class_=\"link_display_like_text\")\n",
    "    company =[]\n",
    "    for j in comp_all:\n",
    "        company.append(j.text.strip())\n",
    "    loc_all = soup.find_all('p',id ='location_names')\n",
    "    location =[]\n",
    "    for l in loc_all :\n",
    "        location.append(l.text.strip())\n",
    "    job_det =soup.find_all('div',class_ =\"item_body\")\n",
    "    j_details=[]\n",
    "    for i in job_det :\n",
    "        job_attr=i.text.strip().replace('\\xa0' ,' ')\n",
    "        j_details.append(job_attr)\n",
    "    start = []\n",
    "    pkg =[]\n",
    "    doj = []\n",
    "    start = j_details[0::3]\n",
    "    pkg = j_details[1::3]\n",
    "    doj = j_details[2::3]\n",
    "    Intern = pd.DataFrame({})\n",
    "    Intern['Company']= company\n",
    "    Intern['Job-Title']=job_title\n",
    "    Intern['Location']=location\n",
    "    Intern['Starts From ']=start\n",
    "    Intern['CTC']=pkg\n",
    "    Intern['Last Date to apply']=doj\n",
    "    \n",
    "    \n",
    "    return Intern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Scrapping Completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Starts From</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Last Date to apply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Softsensor.ai</td>\n",
       "      <td>Salesforce Developer</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>25 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ProtonAutoML</td>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>25 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ProtonAutoML</td>\n",
       "      <td>Business Development Specialist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>25 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RoaDo</td>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>4 - 6 LPA</td>\n",
       "      <td>25 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RavGins International Private Limited (Wobb.ai)</td>\n",
       "      <td>Associate UI/UX Designer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>25 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global Sun</td>\n",
       "      <td>Business Development Associate (Sales)</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4.8 LPA</td>\n",
       "      <td>25 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Touchstone Partners</td>\n",
       "      <td>Receptionist And Billing Manager</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 7 LPA</td>\n",
       "      <td>25 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Labellerr By Tensor Matics Private Limited</td>\n",
       "      <td>Node.js Backend Developer (AWS/GCP/API)</td>\n",
       "      <td>Chandigarh, Mohali</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>7 - 10 LPA</td>\n",
       "      <td>25 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UFaber Edutech</td>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>25 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aptigenz Solutions Private Limited</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>24 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Noise</td>\n",
       "      <td>Management Trainee - Assistant Category Manager</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>6 - 10 LPA</td>\n",
       "      <td>24 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RoaDo</td>\n",
       "      <td>Account Executive - Field Sales</td>\n",
       "      <td>Bangalore, Hyderabad</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3.2 - 4 LPA</td>\n",
       "      <td>25 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CrewKarma</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>24 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IQGateway</td>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3.6 - 10 LPA</td>\n",
       "      <td>24 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Internshala</td>\n",
       "      <td>Social Media Strategist And Copywriter</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>5 - 6.8 LPA</td>\n",
       "      <td>24 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mithi Software Technologies Private Limited</td>\n",
       "      <td>Level 1 Technical Support Engineer</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>White Blink</td>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wono Inc</td>\n",
       "      <td>Accounting Assistant</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>5.4 - 6.1 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wono Inc</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>5.5 - 6.3 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wono Inc</td>\n",
       "      <td>Business Development Manager</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>5.2 - 5.8 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Emertxe Information Technologies</td>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Open Door Education</td>\n",
       "      <td>Product Developer - Mathematics</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>7 - 8 LPA</td>\n",
       "      <td>22 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Content Beta</td>\n",
       "      <td>Sales Development Representative</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>22 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Softway Solutions Private Limited</td>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>5.5 - 9 LPA</td>\n",
       "      <td>22 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DeepThought Edutech Ventures Private Limited</td>\n",
       "      <td>Junior ReactJS Developer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>22 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Saltoro Coffee Roasters</td>\n",
       "      <td>Marketing Manager</td>\n",
       "      <td>Delhi, Noida</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3.2 - 3.5 LPA</td>\n",
       "      <td>22 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WebMOBI</td>\n",
       "      <td>Product Marketing Associate</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>22 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Global Sun</td>\n",
       "      <td>Administration Associate</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>21 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Medico Healthcare Services &amp; Technologies</td>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>21 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Edupixels</td>\n",
       "      <td>Project Coordinator</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>21 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Manufac Analytics Private Limited</td>\n",
       "      <td>Web Developer</td>\n",
       "      <td>Gurgaon, Pune</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Swabhav Techlabs</td>\n",
       "      <td>Software Engineer Trainee</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Claraeon Learning Private Limited</td>\n",
       "      <td>Business Development Specialist (Sales &amp; Marke...</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Picostone</td>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 6.5 LPA</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AIMonk Labs Technology Limited</td>\n",
       "      <td>Associate Front End Developer</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>6 - 7 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>369 Zoss Waters</td>\n",
       "      <td>Corporate Sales Executive</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SleekSky LLC</td>\n",
       "      <td>Associate Software Developer (Full-Stack - Rea...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>4 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>InPhase Power Technologies</td>\n",
       "      <td>Customer Relationship Specialist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Cactus Communications Private Limited</td>\n",
       "      <td>Associate Editor Engagement</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>StrategyCo.Global</td>\n",
       "      <td>Management Consultant Associate</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Starts Immediately</td>\n",
       "      <td>4.5 - 7 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Company  \\\n",
       "0                                     Softsensor.ai   \n",
       "1                                      ProtonAutoML   \n",
       "2                                      ProtonAutoML   \n",
       "3                                             RoaDo   \n",
       "4   RavGins International Private Limited (Wobb.ai)   \n",
       "5                                        Global Sun   \n",
       "6                               Touchstone Partners   \n",
       "7        Labellerr By Tensor Matics Private Limited   \n",
       "8                                    UFaber Edutech   \n",
       "9                Aptigenz Solutions Private Limited   \n",
       "10                                            Noise   \n",
       "11                                            RoaDo   \n",
       "12                                        CrewKarma   \n",
       "13                                        IQGateway   \n",
       "14                                      Internshala   \n",
       "15      Mithi Software Technologies Private Limited   \n",
       "16                                      White Blink   \n",
       "17                                         Wono Inc   \n",
       "18                                         Wono Inc   \n",
       "19                                         Wono Inc   \n",
       "20                 Emertxe Information Technologies   \n",
       "21                              Open Door Education   \n",
       "22                                     Content Beta   \n",
       "23                Softway Solutions Private Limited   \n",
       "24     DeepThought Edutech Ventures Private Limited   \n",
       "25                          Saltoro Coffee Roasters   \n",
       "26                                          WebMOBI   \n",
       "27                                       Global Sun   \n",
       "28        Medico Healthcare Services & Technologies   \n",
       "29                                        Edupixels   \n",
       "30                Manufac Analytics Private Limited   \n",
       "31                                 Swabhav Techlabs   \n",
       "32                Claraeon Learning Private Limited   \n",
       "33                                        Picostone   \n",
       "34                   AIMonk Labs Technology Limited   \n",
       "35                                  369 Zoss Waters   \n",
       "36                                     SleekSky LLC   \n",
       "37                       InPhase Power Technologies   \n",
       "38            Cactus Communications Private Limited   \n",
       "39                                StrategyCo.Global   \n",
       "\n",
       "                                            Job-Title              Location  \\\n",
       "0                               Salesforce Developer                   Pune   \n",
       "1                               Full Stack Developer                 Remote   \n",
       "2                    Business Development Specialist                 Remote   \n",
       "3                       Associate Software Developer              Bangalore   \n",
       "4                           Associate UI/UX Designer                 Remote   \n",
       "5             Business Development Associate (Sales)                 Remote   \n",
       "6                   Receptionist And Billing Manager                 Mumbai   \n",
       "7            Node.js Backend Developer (AWS/GCP/API)     Chandigarh, Mohali   \n",
       "8                     Business Development Executive                 Remote   \n",
       "9                                 Software Developer              Bangalore   \n",
       "10   Management Trainee - Assistant Category Manager                Gurgaon   \n",
       "11                   Account Executive - Field Sales   Bangalore, Hyderabad   \n",
       "12                                 Software Engineer                 Remote   \n",
       "13                      Associate Software Developer                 Remote   \n",
       "14            Social Media Strategist And Copywriter                Gurgaon   \n",
       "15                Level 1 Technical Support Engineer                   Pune   \n",
       "16                      Associate Software Developer                 Remote   \n",
       "17                              Accounting Assistant                 Remote   \n",
       "18                                 Software Engineer                 Remote   \n",
       "19                      Business Development Manager                 Remote   \n",
       "20                    Business Development Executive              Bangalore   \n",
       "21                   Product Developer - Mathematics              Bangalore   \n",
       "22                  Sales Development Representative                 Remote   \n",
       "23                               Full Stack Engineer                 Remote   \n",
       "24                          Junior ReactJS Developer                 Remote   \n",
       "25                                 Marketing Manager           Delhi, Noida   \n",
       "26                       Product Marketing Associate                 Remote   \n",
       "27                          Administration Associate                 Remote   \n",
       "28                      Associate Software Developer              Hyderabad   \n",
       "29                               Project Coordinator                 Remote   \n",
       "30                                     Web Developer          Gurgaon, Pune   \n",
       "31                         Software Engineer Trainee                 Mumbai   \n",
       "32  Business Development Specialist (Sales & Marke...             Hyderabad   \n",
       "33                    Business Development Executive                 Mumbai   \n",
       "34                     Associate Front End Developer              Bangalore   \n",
       "35                         Corporate Sales Executive                 Remote   \n",
       "36  Associate Software Developer (Full-Stack - Rea...             Ahmedabad   \n",
       "37                  Customer Relationship Specialist              Bangalore   \n",
       "38                       Associate Editor Engagement                 Remote   \n",
       "39                   Management Consultant Associate                 Remote   \n",
       "\n",
       "          Starts From             CTC Last Date to apply  \n",
       "0   Starts Immediately      3 - 5 LPA         25 Jul' 21  \n",
       "1   Starts Immediately      3 - 4 LPA         25 Jul' 21  \n",
       "2   Starts Immediately    3 - 3.5 LPA         25 Jul' 21  \n",
       "3   Starts Immediately      4 - 6 LPA         25 Jul' 21  \n",
       "4   Starts Immediately      3 - 4 LPA         25 Jul' 21  \n",
       "5   Starts Immediately    3 - 4.8 LPA         25 Jul' 21  \n",
       "6   Starts Immediately      3 - 7 LPA         25 Jul' 21  \n",
       "7   Starts Immediately     7 - 10 LPA         25 Jul' 21  \n",
       "8   Starts Immediately      3 - 5 LPA         25 Jul' 21  \n",
       "9   Starts Immediately    3 - 3.2 LPA         24 Jul' 21  \n",
       "10  Starts Immediately     6 - 10 LPA         24 Jul' 21  \n",
       "11  Starts Immediately    3.2 - 4 LPA         25 Jul' 21  \n",
       "12  Starts Immediately      3 - 5 LPA         24 Jul' 21  \n",
       "13  Starts Immediately   3.6 - 10 LPA         24 Jul' 21  \n",
       "14  Starts Immediately    5 - 6.8 LPA         24 Jul' 21  \n",
       "15  Starts Immediately          3 LPA         23 Jul' 21  \n",
       "16  Starts Immediately    3 - 3.6 LPA         23 Jul' 21  \n",
       "17  Starts Immediately  5.4 - 6.1 LPA         23 Jul' 21  \n",
       "18  Starts Immediately  5.5 - 6.3 LPA         23 Jul' 21  \n",
       "19  Starts Immediately  5.2 - 5.8 LPA         23 Jul' 21  \n",
       "20  Starts Immediately          3 LPA         23 Jul' 21  \n",
       "21  Starts Immediately      7 - 8 LPA         22 Jul' 21  \n",
       "22  Starts Immediately      3 - 4 LPA         22 Jul' 21  \n",
       "23  Starts Immediately    5.5 - 9 LPA         22 Jul' 21  \n",
       "24  Starts Immediately      3 - 5 LPA         22 Jul' 21  \n",
       "25  Starts Immediately  3.2 - 3.5 LPA         22 Jul' 21  \n",
       "26  Starts Immediately          3 LPA         22 Jul' 21  \n",
       "27  Starts Immediately    3 - 3.2 LPA         21 Jul' 21  \n",
       "28  Starts Immediately    3 - 3.2 LPA         21 Jul' 21  \n",
       "29  Starts Immediately          3 LPA         21 Jul' 21  \n",
       "30  Starts Immediately      3 - 4 LPA         19 Jul' 21  \n",
       "31  Starts Immediately    3 - 3.5 LPA         19 Jul' 21  \n",
       "32  Starts Immediately          3 LPA         23 Jul' 21  \n",
       "33  Starts Immediately    3 - 6.5 LPA         19 Jul' 21  \n",
       "34  Starts Immediately      6 - 7 LPA         18 Jul' 21  \n",
       "35  Starts Immediately      3 - 5 LPA         18 Jul' 21  \n",
       "36  Starts Immediately          4 LPA         18 Jul' 21  \n",
       "37  Starts Immediately    3 - 3.5 LPA         18 Jul' 21  \n",
       "38  Starts Immediately      3 - 4 LPA         18 Jul' 21  \n",
       "39  Starts Immediately    4.5 - 7 LPA         18 Jul' 21  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_chk = \"https://internshala.com/fresher-jobs\"\n",
    "data = wb_scrap(url_chk)\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 .Write a python program to scrape house details from mentioned url. It should include house title, location, area, emi and price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_broker(url):\n",
    "    page = requests.get(url)\n",
    "    print(page)\n",
    "    soup= BeautifulSoup(page.content)\n",
    "    prop_title = soup.find_all('div',class_ ='nb__2JHKO')\n",
    "    title = []\n",
    "    for i in prop_title :\n",
    "        title.append(i.h2.span.text)\n",
    "    sqft = soup.find_all('div',class_='nb__3oNyC')\n",
    "    area = []\n",
    "    for i in sqft :\n",
    "        area.append(i.text)\n",
    "    prop_emi = soup.find_all('div',id ='roomType')\n",
    "    emi = []\n",
    "    for i in prop_emi :\n",
    "        emi.append(i.text)\n",
    "    prop_loc = soup.find_all('div',class_ ='nb__2CMjv')\n",
    "    loc = []\n",
    "    for i in prop_loc :\n",
    "        loc.append(i.text)\n",
    "    prop_price =soup.find_all(\"div\", id =\"minDeposit\")\n",
    "    price = []\n",
    "    for i in prop_price :\n",
    "        j = i.find('div',class_='font-semi-bold heading-6')\n",
    "        price.append(j.text)\n",
    "    NO_BROKER_LIST =pd.DataFrame({})\n",
    "    NO_BROKER_LIST['Availaible'] =title\n",
    "    NO_BROKER_LIST['Locality'] =loc\n",
    "    NO_BROKER_LIST['Total_AREA']=area\n",
    "    NO_BROKER_LIST['Pricre']=price\n",
    "    NO_BROKER_LIST['Monthly_EMI'] =emi\n",
    "    return NO_BROKER_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('**** NO BROKER LIST ****')\n",
    "url = \"https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\"\n",
    "html_chk  =no_broker(url)\n",
    "html_chk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
